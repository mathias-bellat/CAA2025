---
title: "Humans, are you there? Comparative approach of two distinguishable methods for human installation detection: Automatic structure detection and archaeological predictive models"
author:
  - Mathias Bellat:
      correspondence: "yes"
      email: mathias.archaeology@gmail.com
      orcid: 0000-0003-0319-1562
      institute:
        - "CRC 1070 “ResourceCultures”, University of Tübingen"
        - "Department of Geosciences, Chair of Soil Science and Geomorphology, University of Tübingen"
  - Amy Hatton:
      institute: 
        - "Department of Geosciences, Working Group Early Prehistory and Quaternary Ecology, University of Tübingen"
        - "Max Planck Institute of Geoanthropology"
      orcid: 0000-0002-2900-3681
  - Jordy Didier Orellana-Figueroa:
      institute:
        - "Department of Early Prehistory and Quaternary Ecology, University of Tübingen"
        - "High Performance and Cloud Computing Group, University of Tübingen"
      orcid: 0000-0002-2814-6306
title-block-published: "Last updated"  
date: now
date-format: long
format: 
  docx:
    reference-doc: "../templates/template.docx" # Insert path for the DOCX file
execute:
  echo: true
  warning: false
  message: false
  comment: "#>"
  fig-path: "../figures/"
  fig-dpi: 600
filters:
  - ../templates/scholarly-metadata.lua
  - ../templates/author-info-blocks.lua
  - ../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Prediction and detection of archaeological features have long been central topics in archaeological sciences. In recent years, artificial intelligence and machine learning have increasingly complemented - and in some cases replaced - traditional statistical approaches. This paper examines two distinct yet related subfields: automatic archaeological structure detection and archaeological predictive modelling. We systematically reviewed 84 articles, treating these two topics, published between 2005 and 2024, highlighting a sharp rise in publications after 2021, particularly for structure detection studies. Our results reveal the growing predominance of deep learning methods in this area. At the same time, we explore the commonalities between the two approaches, notably their reliance on similar theoretical backgrounds and remote sensing imagery as input data. However, we also identify key differences: predictive models often involve more complex theoretical frameworks and diverse sensor applications, while structure detection is dominated by deep learning models. Finally, we outline potential future directions for both fields based on the trends observed in the reviewed literature.
keywords: |
  machine learning; site detection; review; theory; modelling
highlights: |
  - 84 papers reviewed.
  - Massive development of machine learning approaches since 2021.
  - Disymmetry between automatic structure detection, which dominates, and archaeological predictive models papers.
  - Automatic structure detection approaches are more suited for modern analysis, given their "easier" interpretation.
---

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

<!-- With the following code you can access and display values from the yml header above. -->

Keywords: `r rmarkdown::metadata$keywords`

Highlights: `r rmarkdown::metadata$highlights`

<!-- The actual document text starts here: -->

\newpage

# Introduction

One of the central questions in archaeology lies in understanding the organisation of past societies [@renfrew_archaeology_2020; @trigger_settlement_1967], whether from an intra-site or inter-site perspective. Spatial organisation is a key driver of both present [@levi-strauss_contribution_1936] and past human interactions [@bonnichsen_millies_1973]. Consequently, the relationship between humans and space/place has been explored in depth by archaeologists since the mid-twentieth century [@chang_settlement_1968; @hodder_spatial_1976; @judge_predicting_1988; @kroll_interpretation_1991; @parsons_archaeological_1972; @phillips_method_1953; @willey_prehistoric_1953]. These studies have not only addressed relationships between humans but also human--environment interactions and interdependencies, emphasising the concept of resilience [@keck_what_2013]. The distribution of settlements and other perennial human structures has been a key indicator of these spatial dynamics within societies [@ellis_settlement_1999; @willey_prehistoric_1953]. To investigate such patterns, statistical approaches have been developed to assess spatial dependencies between settlements and environmental factors [@kvamme_one-sample_1990; @trigger_settlement_1967] or to detect distinctive site distributions that may reveal specific social behaviours [@hodder_spatial_1976; @judge_quantifying_1988; @kohler_predictive_1988; @kroll_interpretation_1991].

In parallel, the past decade has witnessed a "data deluge" in archaeology [@bevan_data_2015], evident across subfields such as GIS and remote sensing [@argyrou_review_2022; @davis_aerial_2020], text-based records [@brandsen_information_2023], and machine learning applications [@bellat_machine_2025]. This expansion has been particularly transformative in remote sensing, where airborne laser scanning (ALS or LiDAR) has produced high-resolution imagery capable of penetrating dense vegetation [@bennett_guidelines_2025], and the availability of diverse satellite datasets has greatly increased [@cracknell_development_2018]. Advances in automated detection and segmentation algorithms [@bonhage_modified_2021; @bundzel_semantic_2020; @guyot_combined_2021], improved GIS training for younger generations of archaeologists [@argyrou_review_2022], and the rise of open-science collaborations and networks [@batist_open_2024] have further accelerated this trend.

Although the idea of reducing survey results to binary classifications - "site" or "non-site" - dates back to @willey_prehistoric_1953, the real beginnings of predictive modelling in archaeology emerged in the 1970s and 1980s [@judge_predicting_1988; @thomas_empirical_1973], marking the rise of what has been termed "predictive archaeology" [@verhagen_integrating_2012, p.51]. This approach has been defined as an attempt to predict "the location of archaeological sites or materials in a region, based either on a sample of that region or on fundamental notions concerning human behaviour" [@kohler_predictive_1986], under the "assumption that the location of archaeological remains in the landscape is not random, but is related to certain characteristics of the natural environment" [@verhagen_case_2007, p.13]. With the development of GIS and enhanced computing capacity in the late 1980s [@allen_interpreting_1990; @djindjian_short_2015 ; @verhagen_case_2007, pp.15-16], a new generation of archaeological predictive models (APMs) emerged, designed to map site probabilities [@altschul_models_1984; @kohler_predictive_1988; @kvamme_one-sample_1990; @moon_archaeological_1993; @allen_predictive_1990]. These gave rise to two distinct approaches: inductive (data-driven) models and deductive (theory-driven) ones [@kamermans_predictive_1999; @wheatley_spatial_2013]. The former are constructed from observed variables, such as environmental or anthropogenic factors [@carrer_ethnoarchaeological_2013; @croce_ethnoarchaeological_2025; @ebert_state_2000; @yaworsky_advancing_2020], while the latter rely on expert-defined parameters [@canning_belief_2005]. Yet theory-driven models have remained underdeveloped, often criticised as overly simplistic or "unsophisticated" [@verhagen_integrating_2012]. They also bear strong affinities with agent-based modelling [@lake_explaining_2015], another computational approach in archaeology. The opposition between inductive and deductive methods, rooted in debates of the 1970s, is now increasingly regarded as outdated, both insiders [@kvamme_there_2006; @verhagen_integrating_2012]. and external commentators [@salmon_deductive_1976] view it as more of a historical and epistemological distinction than a current methodological divide.

For the second time, following the development of APMs, new approaches with automated structure detection emerged [@menze_detection_2006], supported by the spread of high-resolution satellite imagery, particularly digital elevation model (DEM) from the shuttle radar topographic mission (SRTM) in 2000 [@farr_shuttle_2007]. This innovative use of ML for the semi-automated detection of archaeological structures was aimed at Tell's, which are large mounded sites, using SRTM data at a resolution of 90 m [@menze_detection_2006]. Despite this early use of ML for site detection, the uptake of this method has only taken place since 2018 [@bellat_machine_2025], thanks to technological innovation and improvements of satellite sensors, combined with the increase in open-access satellite datasets such as Sentinel and Landsat [@zhu_benefits_2019]. Most archaeological structures are smaller than tells and require very-high-resolution satellite data (\< 1 m), in order to be detected. The decreasing cost of drones has allowed them to be adopted by archaeologists for site documentation, which can generate *cm* and even *mm* resolution imagery. Along with all of the improvements in data availability and quality, ML methods saw significant advances in the late 2000's and 2010's, with the development of fast Graphics Processing Units (GPU's) which allowed for renewed interest and development in Deep Learning [@lecun_deep_2015] and Neural Networks aimed at analysing sparse data [@ronneberger_u-net_2015], which archaeological data usually is.

There have been criticisms of ASD, similarly to how APMs were dismissed as lacking in theory. These criticisms are however, enhanced for ML in archaeology due to the black box nature of Machine Learning models, and concern over accuracy and contextualisation of the results [@casana_regional-scale_2014; @opitz_recent_2018]. While these debates are important and will lead to improvements in how ML for ASD is approached, binary questions such as whether a site is present or not in a location do lend themselves to automated approaches, especially when results are properly contextualised and interpreted by experts on the archaeological sites that are detected. The original aim of @menze_detection_2006, to create: "*A comprehensive and accurate listing of these sites*", is still one of the goals of many applications of automatic structure detection. It is a non-destructive tool that allows for archaeological sites to be identified on a far larger scale than would be possible by fieldwork or manual survey of satellite imagery, while also increasing consistency and allowing for documentation of the entire process. It also allows for the detection of sites that have already been destroyed, through the use of historical imagery [@bulawka_deep_2024], the detection of sites in areas that are remote or difficult to access due to political instability [@rayne_detecting_2020], and country-wide detection of sites [@berganzo-besga_hybrid_2021].

From the above mentioned elements, we can ask ourselves two questions: What are the new trends that archaeological predictive models and archaeological structure detection are following? What do they make at the same time, different and similar approaches?

# Methodology

## Article selection

We conducted a rapid systematic review [@jesson_doing_2012] in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines [@page_prisma_2021]. This approach was chosen because it combines a relatively short scoping process with methodological transparency [@haby_what_2016]. Our previous work [@bellat_machine_2025] served as the starting point for this review, to which we added records published in 2023 and 2024. The protocol comprised twelve queries derived from a set of archaeological and machine learning "buzzwords" ([Box 1](#box-01)), which were tested across six online databases: Web of Science, PubMed, Tübingen University Library, German Archaeological Institute, German National Library, and Google Scholar. Records published up to 2022 (*n* = 730) were taken from @bellat_supplementary_2024, while an additional 278 records were collected for 2023 - 2024, resulting in a total dataset of 1,006 records ([Fig. 1](#fig-01)).

The screening process followed two inclusion criteria [@dekkers_setting_2022, pp. 202-208]. First, only peer-reviewed records were retained to ensure methodological consistency. Second, only English-language publications were included, also for consistency. From @bellat_supplementary_2024 dataset, we selected only studies focusing on archaeological predictive modelling or automatic structure detection. For 2023 - 2024, we manually screened titles and abstracts to identify publications that mentioned either of these two approaches.

We then applied two exclusion criteria [@dekkers_setting_2022, pp. 208-209] to refine the dataset. First, we restricted the sample to papers applying machine learning methods, excluding studies based solely on statistical approaches (*e.g.* regression-based methods, hard voting classifiers, and data transformation techniques), in line with related literature [@bzdok_statistics_2018; @bellat_machine_2025; @eleftheriadou_machine_2025]. While statistical methods focus on identifying relationships within datasets, machine learning aims to improve predictions for new data based on prior training [@alpaydin_introduction_2014]. Second, we excluded theory-based and review papers, as these do not provide quantitative results.

In total, our review protocol yielded 85 included articles: 48 from @bellat_machine_2025 and 37 newly collected from 2023 - 2024.

::: {#box-01 .callout-tip collapse="false" title="Box 1: Search query used for the protocol search" appearance="minimal" icon="false"}
Topic = *machine learning \| deep learning \| artificial intelligence \| archaeological \| archeological \| archaeology \| archeology \| archaeo \| archeo*
:::

![Review process from source selection to analysis. Inspired by the PRISMA 2020 flow diagram @haddaway_prisma2020_2022. Reason 1 = Theory or review paper; Reason 2 = Does not involve machine learning techniques/algorithm. Figure created using PRIMA2020 R package and Inkscape.](../figures/Fig.1/Fig.1.png){#fig-01 fig-env="figure" fig-align="center"}

## Data collection

From the reviewed records, we extracted eleven variables, both numerical and categorical ([Tab. 1](#tab-01)). The classification of model families followed @alpaydin_introduction_2014, and @bellat_machine_2025, and @eleftheriadou_machine_2025, while the archaeological subfield of each study was assigned according to the framework established in previous work [@bellat_machine_2025; @kelly_archaeology_2017]. Evaluation methods were grouped into three categories: classification, regression, and clustering [@alpaydin_introduction_2014, pp. 5-13]. Study outcomes were classified as successful, unsuccessful, mixed, affected by methodological issues, or undefined. Additional detail was recorded for pre-training procedures and input data classes.

::: {#tab-01}
|   **Feature**  | **Number of categories** |
|:-----------------:|:--------------------:|
|       Year        |          16          |
|       Model       |          36          |
|    Best model     |          13          |
|      Family       |          8           |
|     Subfield      |          5           |
|    Input data     |          4           |
|    Evaluation     |          3           |
|      Result       |          5           |
|   Pre-training    |          4           |
| Data availability |          3           |
| Code availability |          2           |

Table 1: The eleven features collected systematically from the review.
:::

Then, independently for the APMs records, we also extracted the number of covariates used in the study and the type of feature selection executed, if any. We also extracted the type of performance metrics reported in each study, as well as their associated values ([Fig. 4](#fig-04)). Since many publications did not provide complete metric sets, we computed additional values where possible (*e.g.* from correlation matrices) to enable greater comparability across studies. Specifically, we calculated recall, precision, accuracy, and the F1-score ([Equations 1 - 4](#eq-01)), based on the true or false positives and negatives (TP, TN, FP and FN). In cases where multiple models or study areas were presented, only the highest reported score was retained. Full definitions of all metric acronyms are provided in the glossary.

::: {#eq-01 .grid}
::: g-col-6
$$Recall = \frac{TP}{TP + FP}$$
:::

::: g-col-6
$$Precision = \frac{TP}{TP + FN}$$
:::

::: g-col-6
$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$
:::

::: g-col-6
$$F1-score = 2\cdot\frac{recall \cdot precision}{recall + precision}$$
:::
:::

# Results

From the 85 records analysed, 15 addressed APM approaches and 69 focused on ASD techniques ([Fig. 2](#fig-02)). One study applied two distinct ASD methods, and another used two different APM approaches; these were therefore counted as separate study cases [@agapiou_detection_2021; @li_gis_2024]. A clear trend is visible from 2018 onwards, with at least one publication per year in each application area. This pattern intensified after 2020, with around 75 % of all papers (*n* = 62) published in 2021 or later. The rapid growth of machine learning applications in archaeology since 2018, and particularly from 2020/2021, has also been noted by @bickler_machine_2021, @eleftheriadou_machine_2025 [Fig. 1], and in our previous work [@bellat_machine_2025, Fig. 2].

![Number of publications per year between 2006 and 2024, split between ASDs and APMs (*n* = 84). In light blue, the articles published after 2021 accounted for more than 75% of the publications. Figure generated with R 4.5.0.](../figures/Fig.2/Fig.2.png){#fig-02 fig-env="figure*" fig-align="center"}

Regarding the type of algorithms used, deep learning methods and artificial neural networks (ANNs) are the most represented ones with 59 uses ([Fig. 3](#fig-03)), followed by the ensemble learning models (*n* = 33), in particular, random forest (RF), which is the most prominent model with 28 applications. All other families of machine learning models, Bayesian classifier, linear classifier, unsupervised learning and clustering, decision trees and rule induction, nearest neighbour classifier and polynomial classifier, are more or less, equally represented ([Fig. 3](#fig-03)). The raise of the ANNs can be seen from 2020-2021 onwards (*see* supplementary file) and follow the general trend of publications ([Fig. 2](#fig-02)). There is a high diversity of models used with 36 different algorithms but only half of it have been used more than once. Furthermore, we counted two applications of statistical methods, one linear regression [@fuentes-carbajal_machine_2023] and one k-means clustering [@ben-romdhane_detecting_2023].

![Tree map of the different models used and their related family/group. Figure generated with R 4.5.0.](../figures/Fig.3/Fig.3.png){#fig-03 fig-env="figure*" fig-align="center"}

From the collected performance metrics, we identified 19 unique measures ([Fig. 5](#fig-05)), though only 9 appeared in more than one study. Among ASD applications, recall, precision, and F1-score were reported in 65% of cases (*n* = 45), with accuracy additionally included in 25 of these. Intersection over Union (IoU) was used in 9 studies, mainly in segmentation tasks. For APMs, 68% (*n* = 11) reported Area Under the Curve (AUC), while only three relied on alternative metrics.

![Bar plot of the number of each use of a model family/group per year. Figure generated with R 4.5.0.](../figures/Fig.4/Fig.4.png){#fig-04 fig-env="figure*" fig-align="center"}

We also examined model performance scores by plotting precision against recall for ASD models, including F1-score and accuracy when available ([Fig. 6](#fig-06)). This analysis shows that most studies achieved relatively high performance. The median F1-score was 0.76, while the median accuracy reached 0.86. Precision tended to be slightly higher (median = 0.86) than recall (median = 0.74). However, a subset of studies reported very low precision, which reduced the mean values of both precision and recall to 0.74.

![Number of metrics and metrics score presented in the reviewed papers (*n* = 66). Some papers did not present any metrics. The different metrics are represented on the left, and the case study name is at the bottom. Blue gradient indicates the number of metrics used for one case study, with a minimum of 1 and a maximum of 6. APM papers are highlighted by an orange rectangle. Figure generated with R 4.5.0 and modified with Inkscape, inspired by @eleftheriadou_machine_2025.](../figures/Fig.5/Fig.5.png){#fig-05 fig-env="figure*" fig-align="center"}

![Scatter plot of the recall - precision score for the archaeological structure detection records, numbered according to the ID-number of the study. F1-score is represented by the size of the point, and accuracy is shown with a gradient colour when available (*n* = 45). Figure generated with R 4.5.0 and modified with Inkscape.](../figures/Fig.6/Fig.6.png){#fig-06 fig-env="figure*" fig-align="center"}

# Discussion

## Common elements

From a theoretical perspective, both archaeological predictive models and archaeological structure detection share a common conceptual background. At their core lies the notion of site probability [@gillies_human-centred_2016; @hodder_spatial_1976; @willey_prehistoric_1953], rooted in the fundamental archaeological question of why "populations located sites where they did" [@kvamme_analysing_2020, p. 213]. Both approaches address this question by attempting to predict site locations. Judge and Lynne defined prediction as "*the ability to foretell on the basis of observation, experience, or scientific reason*" [@judge_quantifying_1988, p. 2]. This predictive dimension was explicitly present in the early stages of APMs [@verhagen_integrating_2012], and is even reflected in their name, but it is less immediately visible in the terminology of ASD. Nevertheless, one of the earliest works to apply predictive modelling for archaeological structure detection in remote sensing imagery - @menze_detection_2006 on Syrian tells - explicitly framed the task as the need for "*a comprehensive and accurate listing of these sites*" effectively operationalising presence/absence prediction in a way analogous to APMs.

Another key similarity between APMs and ASDs lies in their reliance on remote sensing data, whether derived from UAVs [*e.g.* @monna_machine_2020; @orengo_brave_2019; @sakai_ai-accelerated_2024] , aircraft [*e.g.* @bonhage_modified_2021; @guyot_combined_2021; @lidberg_detection_2024], or satellites [*e.g.* @caspari_convolutional_2019; @castiello_explorative_2021; @karamitrou_identification_2023]. The rise of both applications is closely tied to the broader expansion of remote sensing in archaeology [@argyrou_review_2022], itself driven by the rapid increase in Earth observation satellites since 2015 ([Fig. 7.C](#fig-07)). This growth has also been fuelled by greater accessibility to satellite and LiDAR datasets, as well as by major improvements in image resolution, particularly from modern airborne laser scanning (ALS) platforms (0.5 - 1 m resolution) and UAVs. Future developments in remote sensing are likely to further enhance archaeological applications, not only through sensor advances but also through computational methods such as super-resolution techniques [@liu_remote_2025; @wang_comprehensive_2022].

![**A**: Number of records in the archaeological field mentioning remote sensing on the Dimension database. **B**: Number of records in the archaeological field mentioning remote sensing on the Web of Science database. **C**: Number of satellites dedicated to earth observation launched per year, according to the USC database, we did not take military satellites into account. Figure generated with R 4.5.0.](../figures/Fig.7/Fig.7.png){#fig-07 fig-env="figure*" fig-align="center"}

Despite differences in the types of models employed in APMs and ASDs, both fields show a strong reliance on the RF algorithm. In ASD tasks, RF accounts for nearly 20 % of applications (*n* = 18), while in APMs it represents 41 % (*n* = 10). The prominence of RF in archaeological machine learning is unsurprising: the method is relatively straightforward to implement and can be applied flexibly to both classification and prediction problems [@breiman_random_2001].

## Differences in the approaches

While APMs and ASDs share a number of similarities, important differences explain why they have followed distinct research trajectories. From a theoretical standpoint, APMs benefit from a more established background built over more than 40 years of practice [@judge_predicting_1988; @kvamme_analysing_2020]. They have also faced criticism, particularly for their perceived "deterministic" nature [@kamermans_deconstructing_2004; @kvamme_there_2006], reflecting their strong roots in ecological science [@yaworsky_neanderthal_2024]. By contrast, ASDs have been less subject to such criticism, as they are more data-driven and object-focused. Their main limitations concern their ability to connect with broader archaeological questions and engage a wider audience [@davis_object-based_2019; @davis_defining_2020; @davis_theoretical_2021]. However, the past five years have seen growing interest in ASDs [@bennett_guidelines_2025]. The OpenAI to Z Challenge is one example of bridging a "niche" method with public engagement, aiming to locate archaeological sites in the Amazon using large language models and computer vision tools with OpenAI o3/o4 mini and GPT-4.1 <https://openai.com/openai-to-z-challenge/>.

Differences are also evident in the use of machine learning methods. ASD studies frequently employ artificial neural networks (ANNs; *n* = 57), particularly U-Net [*e.g.* @anttiroiko_detecting_2023; @bundzel_semantic_2020; @garcia-molsosa_potential_2021], convolutional neural networks [CNNs @gallwey_bringing_2019; @ikaheimo_detecting_2023; @soroush_deep_2020], and their region-based or mask-based variants [*e.g.* @bonhage_modified_2021; @quintus_evaluating_2023; @verschoof-van_der_vaart_learning_2019]. In contrast, our review found only two APM studies using ANNs [@oonk_supervised_2015; @wang_archaeological_2023]. Bayesian classifiers also show divergent use: MaxEnt appears exclusively in APMs [*e.g.* @benner_combining_2019; @imen_utilizing_2024; @wang_archaeological_2023], given its suitability for handling pseudo-absence data [@yaworsky_advancing_2020].

Another major difference lies in the input data. ASD typically relies on single-image datasets [LiDAR, UAV, or satellite imagery, @altaweel_automated_2022; @guyot_combined_2021]. This choice is partly due to the finer resolution of such imagery (\< 10 m), suited to detecting small structures, and partly to the suitability of deep learning models for image recognition. By contrast, APMs often integrate multiband datasets - including DEMs, spectral information, and soil chemistry - with more than ten covariates commonly included [@oonk_supervised_2015; @castiello_explorative_2021]. The number of covariates is less limited as the process do not need recognition but prediction based on pixel values. Feature selection, reduction of the number of input data ([Fig. 8](#fig-08)), is often applied for simplifying the model and increasing transposability, either through expert-driven choices [@friggens_predicting_2021; @hansen_prioritizing_2020] or statistical methods [@oonk_supervised_2015; @wang_archaeological_2023; @yaworsky_advancing_2020].

![Number of covariates used in the APMs papers reviewed and the type of feature selection selected (*n* = 13). Figure generated with R 4.5.0.](../figures/Fig.8/Fig.8.png){#fig-08 fig-env="figure*" fig-align="center"}

Interpretability also differs markedly. ASD, especially when based on deep learning, is often considered a "black box" because the contribution of individual features is unclear [@bickler_machine_2021]. Recent progress in explainable AI (XAI) has improved transparency, for example, through saliency maps that highlight which areas of an image drive predictions [@barredo_arrieta_explainable_2020; @xu_explainable_2019]. However, XAI remains relatively uncommon in ASD. In contrast, APMs naturally lend themselves to interpretation, as the influence of each covariate can be quantified and visualised [@li_gis_2024].

Finally, APMs generally follow a well-established and relatively lightweight workflow requiring limited computational resources, reflecting their long-standing use in archaeology. By contrast, ASD research is less standardised, employing a wide range of models and metrics ([Fig. 3,](#fig-03) [4](#fig-04) [and 5](#fig-05)). This diversity is unsurprising given its recent and rapidly evolving development. Over time, ASD workflows may become more structured as the field matures. However, they remain computationally demanding, requiring substantial time and resources despite the accessibility of cloud platforms such as Google Colab.

# Conclusion

This review has examined recent developments and trends in two distinct AI-based approaches in archaeology: archaeological structure detection and archaeological predictive modelling. Our survey, based on a reproducible methodology, covers studies published from the mid-2000s to 2024. As in other subfields of AI in archaeology, ASD has attracted growing interest since 2020, while APM has not yet fully embraced the AI transition, with relatively few studies adopting such methods.

The dominance of artificial neural networks in ASD reflects the suitability of deep learning for image recognition. Convolutional neural networks, and particularly MR-CNNs, have proven highly effective for detecting archaeological features and are now widely used. By contrast, APMs continue to rely on more established approaches, such as Bayesian classifiers (*e.g.*, MaxEnt) and ensemble learning with random forests. Progress in explainable AI is expected to improve the interpretability of deep learning, which will particularly benefit ASD applications.

Our comparison has highlighted both theoretical and methodological differences ([Tab. 2](#tab-02)). APMs build on a long-standing research tradition and tend to employ more standardised workflows, while ASD remains less structured and more experimental. The diversity of input data also distinguishes the two approaches: APMs integrate multiple covariates (*e.g.*, DEMs, spectral data, climate variables), providing a broader picture of past landscapes, whereas ASD focuses mainly on single-band imagery (LiDAR, aerial or satellite data). ASD tasks also demand greater computational resources in terms of time and processing power.

::: {#tab-02}
| **Element** | **Archaeological predictive model** | **Automatic structure detection**|
|:-----------------|:------------------------:|:--------------------------:|
| Strong theoretical background and foundations | True, with developed literature|Very few Access to the input data|
| Number of input data|Exhaustive, all possible landscape features| Often limited to a single band due to model design|
| Pre-treatment|      Mixed, feature selection and sampling selection can occur       |                   Limited data augmentation in a few cases                   |
| Model complexity                              |        Low, ensemble learning and Bayesian classifier models         |           High, neural network models with millions of parameters            |
| Time needed                                   |     Low, limited time needed for local and regional-based model      |    High, large amount of time needed for deep learning computation model.    |
| Cost                                          |                               Low cost                               | Low to high cost in case of complex image recognition needing GPU capacities |
| Model interpretability                        |           High, with each feature's influence on the model           |              Low, neural network models acting as "black boxes"              |
| Metrics                                       |                     Few of the metrics available                     |        Numerous metrics available depending on the segmentation task         |
| Result interpretability                       | Limited, prediction maps and binary maps can be computed when needed |                             Easy to read results                             |
| Adaptability                                  |                    Limited to a type of landscape                    |                   Limited to the type of structure studied                   |

Table 2: Summary of various aspects of ASD and APM approaches.
:::

From this review, several future directions can be identified :

1.  The availability of larger datasets will encourage further applications in APMs. For ASD, given that imaging resolution has already reached near-critical levels, the most promising developments lie in open-access data, FAIR principles, and shared databases [@casillo_artificial_2025].

2.  More standardised and collaborative workflows, supported by platforms such as GitHub or Google Colab [@batist_open_2024], will enhance reproducibility and strengthen the scientific foundations of both approaches [@marwick_is_2025].

3.  Site detection offers a clear binary outcome, "site or not", APMs provide probabilistic predictions, yet remain limited by the challenge of defining true absence data [@kamermans_deconstructing_2004; @mcdonald_site-based_2015].

4.  Commercial applications are also likely to diverge. ASD is increasingly applied in practice, with dedicated workflows such as the ADAF model [@coz_earthobservationadaf_2024; @coz_advancing_2025]. By contrast, APMs have long sought but rarely secured a consistent role in cultural heritage management [@deeben_beyond_1997; @espa_gis_2006], due to both methodological challenges and administrative constraints [@kamermans_predictive_1999; @kamermans_smashing_2008; @verhagen_case_2007].

Finally, both ASD and APM will inevitably need to address broader concerns surrounding the ethical use and development of artificial intelligence. As these methods mature, balancing technological innovation with responsible practice will remain a central challenge for the future of AI in archaeology.

[**Author contributions:**]{.underline} M.B. and A.H., conceived the idea for the manuscript and initiated and designed the research. M.B., A.H. and J.D.O.F., collected data and selected the articles. M.B. and A.H., performed the statistical analysis and interpreted the results. M.B., A.H. and J.D.O.F., wrote the manuscript, with critical input from all co-authors. M.B., A.H. and J.D.O.F., reviewed the manuscript.

[**Acknowledgements:**]{.underline} This work has received funding from the Deutsche Forshungemeischaft (DFG) Collaborative Research Center (CRC) 1070 "ResourceCultures", grant agreement n°215859406. Conflict of interest statement: The authors declare no conflict of interest.

[**Data availability statement:**]{.underline} The data used in this study are openly available on the Zenodo repository at [https://doi.org/10.5281/zenodo.17095617](https://doi.org/10.5281/zenodo.17095617).

[**Declaration of Generative AI and AI-assisted technologies in the writing process:**]{.underline} During the preparation of this work, the authors used ChatGPT 4.5 [@brown_language_2020] in order to generate part of the R code and improve English writing. After using this tool, the authors reviewed and edited the content as needed and took full responsibility for the content of the publication.

\newpage

# Annexes

```{r annexes, echo = FALSE, error = FALSE}
library(readxl)
library(dplyr)
library(flextable)

getwd()
# 1.1 Import the data ==========================================================
df <- read_excel("../data/raw_data/Statistics_papers.xlsx", sheet = "Models statistics")
df <- df[-109,-c(6:10)]
df <- df[df[3] !=0,] # Remove models with no occurences

# 1.2 Format the data ==========================================================
df_counted <- df[,c(1:5)]
names(df_counted) <- c("description", "model", "value", "value.best", "family")
df_counted$family[df_counted$family == "N/A"] <- "Statistics" 

df_counted$approach <- "Machine learning"
df_counted$approach[df_counted$family == "Statistics"] <- "Statistics" 
df_counted$family[df_counted$model == "LR"] <- "Linear regression"
df_counted$family[df_counted$model == "k-MC"] <- "Dimensionality reduction"

df_counted <- select(df_counted, approach, family, description, model, value, value.best)
df_counted <- df_counted %>%  arrange(approach, family, desc(value))

# 1.3 Plot the table ===========================================================
# use the html format for the html quarto file and the latex format for the word and pdf

flextable(df_counted) %>%
    set_header_labels(
    approach = "Approach",
    family = "Family",
    description = "Description",
    model_abbr = "Model abbreviation",
    num_uses = "Number of uses",
    num_best = "Number of times the model performed the best"
  ) %>%
  set_caption(caption = "List of algorithms used in the papers under review organized by the approach and family of analysis, along with their abbreviations and number of use. In the case the model was compared to others, we highlighted the number of time he performed as the best model.") %>%
  merge_v(j = c("approach", "family")) %>%
  autofit()
```

\newpage

# References

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

::: {#refs}
:::
